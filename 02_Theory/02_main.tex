\chapter{Theory}

In the following chapter, the necessary theory to understand this work and its analysis is presented. The explanations below are not meant to be exhaustive, rather the minimal set of information needed for comprehension. For readers seeking more information, additional sources are cited.

To start, a high-level overview of Density Functional Theory is presented, followed by a quantum mechanical technique called Wannierization. Finally, an introduction to force fields is provided to better elucidate the goals of this research.

Certain assumptions are made regarding the reader's background knowledge. A certain familiarity with quantum mechanics and solid state physics is assumed. Specifically, it is assumed the reader is familiar with enough quantum mechanics to understand the quantum description of the hydrogen atom and the concepts of the unit cell, reciprocal space, and Bloch functions. 

\section{Density Functional Theory}

Density Functional Theory (DFT) is a quantum mechanical technique used to the solve interacting many-body problem and attain an approximation for the groundstate wavefunction of a system [\textbf{bird's eye view of dft paper}]. However, to truly appreciate what DFT has to offer, first consider a system of ions and electrons, totally $N$ bodies. Solving any equations for such a system is a $3N$ dimensional problem. This dimensionality can be (drastically) reduced (in the case of large $N$) if one considers rather the ion and electron densities. Since the Born-Oppenheimer (BO) approximation is typically invoked\textemdash that is, the ionic and electronic systems can be decoupled\textemdash this reduces the problem to solving for a 3-dimensional wavefunction.

    \subsection{Hohenberg-Kohn Theorems} 
    
    The theoretical underpinning for DFT comes from the Hohenberg-Kohn (HK) theorems. They are as follows: (HK-1) There exists a one-to-one mapping between the groundstate electron density $n(\Vec{r})$ and the groundstate wavefunction $\psi (\Vec{r})$ for a non-degenerate groundstate, and (HK-2) The groundstate density $n_0(\Vec{r)}$ minimizes the total energy. [\textbf{HK 1964 paper}]
    
    Taken together, the HK theorems provide a road map for solving the interacting many-body problem. Rather than treating each interacting body explicitly, the electron \textit{density} of the groundstate is sought. Once that is determined, a simple mapping is applied to attain the groundstate wavefunction $\psi_0$.
    
    Note, the first HK theorem (HK-1) is in essence an existence theorem, not a construction theorem. Rather than identify the specific mapping between groundstate density and groundstate wavefunction, it proves that such a mapping exists. To construct such a mapping, one uses the Kohn-Sham equation.
    
    \subsection{Kohn-Sham Equation} 
    
    The Kohn-Sham (KS) equation is a single-particle, Schr√∂dinger-like equation for a fictitious system of non-interacting particles that produces the same groundstate density as the interacting many-body system. It takes the form
    
    \begin{equation}
        \label{eq:ks}
        \left[-\frac{\hbar^2}{2 m}\nabla^2 + V_\text{eff}(\Vec{r}) \right]\phi_i(\Vec{r}) = \varepsilon_i \phi_i(\Vec{r}),
    \end{equation}
    
    \noindent for reduced Planck constant $\hbar$, electron mass $m$, gradient operator $\nabla$, an effective potential $v_\text{eff}$, and fictitious KS-orbitals $\phi_i$ with corresponding KS-energy $\varepsilon_i$. (Note, again the BO approximation is invoked here.) The density of the original $N$-body problems is related to the fictitious KS-orbitals by
    
    \begin{equation}
        n(\Vec{r}) = \sum\limits_{i=1}^N |\phi_i(\Vec{r}) |^2
    \end{equation}
    
    The total energy for the KS-system is given by
    
    \begin{equation}
    \label{eq:func1}
        E[n] = T[n] + E_\text{ext}[n] + E_\text{H}[n] + E_\text{xc}[n],
    \end{equation}
    
    \noindent with KS-kinetic energy
    
    \begin{equation}
    \label{eq:func2}
        T[n] = \sum\limits_{i=1}^N \int \phi_i^*(\Vec{r})\left(-\frac{\hbar^2}{2m}\nabla^2 \right)\phi_i(\Vec{r})d\Vec{r},
    \end{equation}
    
    \noindent external energy using the system-specific external potential $\nu_\text{ext}$
    
    \begin{equation}
        E_\text{ext}[n] = \int \nu_\text{ext}(\Vec{r}) n(\Vec{r})d\Vec{r},
    \end{equation}
    
    \noindent Hartree/Coulomb correlation 
    
    \begin{equation}
    \label{eq:func3}
        E_\text{H}[n] = \frac{e^2}{2}\int\int \frac{n(\Vec{r})n(\Vec{r'})}{|\Vec{r} - \Vec{r'}|}d\Vec{r}d\Vec{r'}, 
    \end{equation}
    
    \noindent and exchange-correlation (xc) energy $E_\text{sc}$ which is discussed in detail below. 
    
    (As a nomenclature note, eqs. (\ref{eq:func1}-\ref{eq:func3}) are functionals as denoted by the use of $[\text{ }]$. Put simply a functional is a function that takes other functions, such as the density $n(\Vec{r})$, as inputs.)
    
    The latter three terms in (\ref{eq:func1}) are related to what is often called the KS-effective potential
    
    \begin{equation}
        V_\text{eff}(\Vec{r}) = \nu_\text{ext}(\Vec{r}) + \frac{e^2}{2}\int \frac{n(\Vec{r'})}{|\Vec{r}- \Vec{r'}|} d\Vec{r'} + \nu_\text{xc}(\Vec{r}),
    \end{equation}
    
    \noindent with the xc-potential $\nu_\text{xc}$ defined as
    
    \begin{equation}
        \nu_\text{xc}(\vec(\vec{r})) = \frac{\partial E_{xc}[n(\vec{r})]}{\partial n(\vec{r})},
    \end{equation}
    
    \noident which encompasses all other many-body interactions and is the only component that is not known exactly.
    
    \subsection{Exchange-Correlation Functional}
    
    Broadly stated, exchange-correlation refers to all of the interactions between the many-bodies with corresponding xc-energy $E_\text{xc}$. In the case of electrons, the exchange refers to the well-known Pauli exclusion principle, and the correlation refers to all other correlations with the exception of the Hartree/Coulomb correlation, for which eq. (\ref{eq:func3}) already accounts. The corresponding energy is thus
    
    \begin{equation}
        \label{eq:xc_energy}
        E_\text{xc}[n(\Vec{r})]= \int \left\{ \varepsilon_\text{x}[n(\Vec{r})] + \varepsilon_\text{c}[n(\Vec{r})]\right\} n(\vec{r})d\vec{r},
    \end{equation}
    
    \noindent with exchange potential $\varepsilon_\text{x}$ and correlation potential $\varepsilon_\text{c}$.
    
    As the use of phrases such as "all other correlations" may suggests, eq. (\ref{eq:xc_energy}) is not known exactly and is where errors are introduced to DFT. Collectively, these potentials are known as the xc-functional $\varepsilon_\text{xc} = \varepsilon_\text{x} + \varepsilon_\text{c}$ and approximations must be used.
    
    \paragraph{Local-Density Approximation} One of the more basic approximations is the Local-Density Approximation (LDA), which depends solely upon the electron density at a given point
    
    \begin{equation}
        \varepsilon_\text{xc}[n(\vec(r))] \approx \varepsilon_\text{xc}^\text{LDA}[n(\vec(r))].
    \end{equation}
    
    \noindent Here, $\varepsilon_\text{xc}^\text{LDA}$ is the xc-functional for a homogeneous electron gas (HEG) with density $n$. An analytic form of the exchange component is known, but the correlation component is only known exactly in limiting cases [\textbf{bird's eye view}]. 
    
    \paragraph{Generalized Gradient Approximation} Implicit in the description above, the LDA assumes that the density does not vary, or put differently, the gradient of the density vanishes. While this is true in the case of the HEG, it is not generally so, and this discrepancy often manifests itself by (under-) over-estimating the (exchange) correlation energy [\textbf{10.1063/1.4869598}]. To combat this, the LDA functional is expanded to include the gradient of the density 
    
    \begin{equation}
    \label{eq:gga}
        \varepsilon_\text{xc}[n(\vec(r))] \approx \varepsilon_\text{xc}^\text{GGA}[n(\vec(r)),\nabla n(\vec(r))].
    \end{equation}
    
    \noindent Conceptually, this can be thought of as the first correction to the Taylor expansion of the density at point $\vec{r}$. While one could in theory use as many terms in this expansion as desired, this work uses functionals of the form (\ref{eq:gga}) throughout.
    
    \subsection{Variational Principle}
    
    Before putting all of the above theoretical pieces together, one more piece is needed to form an high-level understanding of DFT\textemdash the variational principle. From calculus of variations, it is known that any physical quantity that depends on a set of equations can be optimized by an element in that set. The generalized methods by which this function is obtained is referred to as the variational principle [\textbf{ISBN 0-8020-1743-6}]. Note, an implicit assumption in the above statement is that the quantity, or observable, being measured is bound on at least one end.
    
    To unpack this definition contextually, consider the energy $E$ of some quantum mechanical system, which is a functional of the wavefunction $\psi$
    
    \begin{equation}
    \label{eq:en_var}
        E \rightarrow E[\psi(\vec{r})].
    \end{equation}
    
    \noindent Knowing that the system has some groundstate energy $E_0$ described by some groundstate wavefunction $\psi_0$, the energy value in (\ref{eq:en_var}) is strictly greater than or equal to the true groundstate energy. That is,
    
    \begin{equation}
        \label{eq:varprinc}
        E_0 = E[\psi_0(\vec{r})] \le E[\psi(\Vec{r})].
    \end{equation}
    
    Equation (\ref{eq:varprinc}), coupled with the HK theorems, hints at a protocol for approximating the groundstate energy, and therefore wavefunction. This protocol is summarized below.
    
    \subsection{Algorithm Summary}
    
    Before presenting the algorithm, consider what is known:
    
    \begin{itemize}
        \item There exists a one-to-one mapping between the groundstate wavefunction $\psi_0$ and the groundstate electron density $n_0(\Vec{r})$, and $n_0(\Vec{r})$ minimizes the total energy (e.g. gives the groundstate energy $E_0$). (HK 1-2)
        \item The groundstate density $n_\text{KS}(\Vec{r})$ of the fictitious KS system is the same as the groundstate density $n_0(\Vec{r})$ of the quantum system. 
        \item Any trial wavefunction $\psi(\Vec{r})$ corresponds to energy greater than or equal to the groundstate energy.
    \end{itemize}
    
    \noindent Leveraging the above information, the following self-consistent algorithm is implemented in DFT.
    
    \begin{enumerate}
        \item An initial guess of the density $n_k(\Vec{r})$ is made.
        \item The effective potential $V_\text[n_k(\vec{r})]$ is evaluated.
        \item The KS equation (\ref{eq:ks}) is solved.
        \item The new density is calculated $n_{k+1}(\Vec{r}) = \sum\limits_{i=1}^N |\phi_i(\vec{r})|^2$.
        \item The following statement is evaluated as True of False for some tolerance $\delta$:
    \end{enumerate}
    
    \begin{equation}
    \label{eq:self_con}
        |n_{k}(\vec{r}) - n_{k+1}(\vec{r})| \le \delta.
    \end{equation}
    
    \noindent In the event that (\ref{eq:self_con}) is not true, steps 1-5 are repeated using $n_{k+1}(\Vec{r})$ as the trial density, and this process continues until self-consistency is achieved. Once achieved, the wavefunction associated with the self-consistent density is determined to be the groundstate.
    
    While the exact subroutines that accomplish steps 1-5 vary by implementation, they are not necessary for the understanding, and are beyond the scope, of this work. Even with these black boxes, though, a high-level appreciation for the DFT approach is possible.

\section{Wannierization}

Wannierization is generally used to describe a change of basis transformation from one basis set to Wannier functions, which can serve as a basis set for periodic solids. Consider, for instance, the commonly used basis set comprised of Bloch orbitals

\begin{equation}
\label{eq:wan_1}
    \Psi_{n,\vec{k}}(\Vec{r}) = e^{i\Vec{k}\cdot\Vec{r}} e^{i\varphi_n(\vec{k})} u_n(\vec{r}), 
\end{equation}

\noindent for wavenumber $\vec{k}$, arbitrary phase factor $e^{i\varphi_n(\vec{k})}$, and some function $u_n(\vec{r})$ with the same periodicity as the structure. The Wannier function (WF) is found by applying a unitary transformation, yielding

\begin{equation}
\label{eq:wan_2}
    w_{n,\vec{R}}(\Vec{r}) = \frac{V}{(2\pi)^3} \sum\limits_{\Vec{k}}  \Psi_{n,\vec{k}}(\Vec{r}) e^{-i\Vec{k}\cdot\Vec{R}} e^{i\varphi_n(\vec{k})},
\end{equation}

\noindent for specific lattice site $\vec{R}$. Note, the similarities between (\ref{eq:wan_1}) and (\ref{eq:wan_2}) and that of a Fourier transformation. In both, a mapping between real- and reciprocal space occurs. In fact, in the case of Wannierization, the Bloch orbitals, which are localized in reciprocal space, are transformed into Wannier functions, which are localized in real space.

It is worth noting that the WF (\ref{eq:wan_2}) is not unique due to the arbitrary phase factor $e^{i\varphi_n(\vec{k})}$, but this arbitrariness is exploited to choose a WF that minimizes the \textit{spread} $\Omega$, which is defined by

\begin{equation}
    \Omega \equiv \sum\limits_n \left[ \langle r^2 \rangle_n - \langle r \rangle^2_n \right]
\end{equation}

\noindent Such WFs, known as maximally localized wannier functions (MLWFs) are extremely useful to understand the system chemically and can be thought of as the conceptual analog to molecular orbitals in periodic solids [\textbf{wannier review}].


There exist many reasons for doing such a transformation (see [\textbf{wannier review} for extensive review of theory and applications), but the impetus for this study lies in partial change analysis. It turns out the the centers of the MLWFs can be thought of as the classical location for the point charge, and the sum of all of the centers is related to the polarization [\textbf{wannier review}]. More details on how this technique is utilized are given in the Chapter \ref{ch:part_char}.

Again, the actual subroutines implemented to calculated the MLWFs and their corresponding centers are treated as a black box for the purposes of this study.

\section{Force Fields}

There are many reasons why one would want to avoid using the DFT techniques described above when computationally investigating a system. For starters, DFT calculations generally require significant computational resources, to the point that running certain calculations in this require access to some type of cluster. There are benefits to this higher cost though, specifically the electronic subsystem's degrees of freedom are in fact free. When trying to calculate the effect on a molecule's dipole in the presence of other atoms, for example, it is necessary that the electronic subsystem can interact.

What if, though, the obversable of interest in not dependent explicitly on the electronic subsystem\textemdash say, the dynamics of $N$ molecules in a box of volume $V$. Here, fluctuations in the electronic subsystem are assumed negligible for purposes of interaction calculations, and it is reasonable to assign point charges to the atoms, effectively freezing the electronic degrees of freedom. 

Assigning such a point charge dramatically decreases computational cost, because the expensive DFT procedures can be skipped. But it immediately begs the question: how much charge do you assign to each atom? The process by which this question is answered is known as parameterization.

    \subsection{Parameterization}
    
    In generally, parameterization is the process by which the total energy $E_T$ of a system is decomposed into independent contributions, namely bonded and non-bonded energy
    
    \begin{equation}
        E_T = E_B + E_N.
    \end{equation}
    
    \noindent The bonded and non-bonded energies can each be further decomposed (into bond, angle, and dihedral energies; and van der Waals and Coulomb energies respectively), wherein each one of these energies corresponds to a certain interaction.
    
    \begin{figure}
        \centering
        \includegraphics[width=0.7\linewidth]{Figures/System/water-molecule.jpg}
        \caption{Depiction of a water molecules with one oxygen atom (red) and two hydrogen atoms (silver). The two covalent bonds are indicated by a white bar. [\textbf{turbosquid.com}]}
        \label{fig:water_molecule}
    \end{figure}
    

        \paragraph{Ex: H$_2$O Molecule Force Field}

        To unpack this rather convoluted general definition, consider the case of a water molecule as shown in Fig. \ref{fig:water_molecule}. Between the oxygen atom (red) and each of the hydrogen atoms (silver), there exists a bond potential, given by
        
        \begin{equation}
        \label{eq:bond_param}
            E_\text{bond} = k_b(|\vec{r}|=|\vec{r_0}|),
        \end{equation}
        
        \noindent for separation vector $\vec{r}$, equilibrium separation vector $\vec{r_0}$, and bond parameter $k_b$. In order to use (\ref{eq:bond_param}), values must be provided for the bond parameter and the equilibrium separation vector.
        
        Similarly, one can imagine an angle potential corresponding to the expansion and contraction of the OHO angle $\theta$
        
        \begin{equation}
            E_\text{ang} = k_a(\theta - \theta_0),
        \end{equation}
        
        \noindent for angle parameter $k_a$ and equilibrium OHO angle $\theta_0$. Again, both of these require a numeric value to be of any use. Finally, each atomic species has a partial charge assigned to it, such that the total charge vanishes.
        
        \paragraph{Tuning Parameter Value} There are numerous options for determining the parameter values, but the general procedure is the same. Some initial guess is made, typically in reference to a value from experiment or more-accurate quantum calculation, and an experiment is performed to measure an observable. For instance, the in the case of the water molecule, and box of water may be simulated at ambient conditions and the density of water molecules is measured. This measured density can be compared to the reference value, and if the results are not satisfactory, the parameters are adjusted slightly and the experiment is repeated.
        
        In this work, a variant of this procedure is followed.
